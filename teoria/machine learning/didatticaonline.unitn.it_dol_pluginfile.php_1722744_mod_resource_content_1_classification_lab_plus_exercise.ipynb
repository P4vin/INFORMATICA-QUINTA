{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpFnK5oYr8_X"
   },
   "source": [
    "# Intro2ML 2023 - Classification\n",
    "## Nicola Dall'Asen\n",
    "### nicola.dallasen@unitn.it\n",
    "In this notebook we will learn by examples how to perform classification using different algorithms:\n",
    "- KNN\n",
    "- Decision trees\n",
    "- Random forests\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THlX458KU9S1"
   },
   "source": [
    "## Classification of handwritten digits\n",
    "In this document we address a classification task. The goal is to find a function $f\\in\\mathcal Y^\\mathcal X$ that given an input $x\\in\\mathcal X$ provides a class label $f(x)\\in\\mathcal Y$ in a way that to best fit some pre-defined (unknown) data distribution on $\\mathcal X\\times\\mathcal Y$. More specifically, we address the problem of classifying handwritten digits. Accordingly, the input space $\\mathcal X$ consists of gray-scale images of fixed resolution $h\\times w$ representing handwritten digits from $0$ to $9$, and the label space is given by $\\mathcal Y=\\{0,\\ldots,9\\}$. Below we see some examples:\n",
    "![Examples from MNIST](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
    "\n",
    "To get a representative sample of the distribution of handwritten digits, we consider a well-known dataset in the field called [MNIST](https://en.wikipedia.org/wiki/MNIST_database), which contains $70$k gray-scale images of handwritten digits from $0$ to $9$, each image being $28\\times 28$ (so, $w=h=28$). \n",
    "\n",
    "Our goal in this document is to play with different machine learning algorithms, rather than pursuing the best absolute performance on this dataset. Accordingly, we will consider a subset of $20$k images that we split $10$k images for training, $5$k for validation and $5$k for test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is5rw9HBbb7I"
   },
   "source": [
    "## MNIST\n",
    "\n",
    "We start by loading and inspecting the MNIST dataset. To this end, we make use of scikit-learn to fetch MNIST's data. Note that the following instructions will take several seconds for the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuwVToL0kxtV"
   },
   "outputs": [],
   "source": [
    "# Import the function to fetch MNIST from scikit-learn\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Fetching MNIST data by returning digit images and targets in two tensors\n",
    "# We call the tensor with input data X and the relative targets y\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qidCGeKKpplb"
   },
   "source": [
    "We next inspect the tensors we have and convert them from NumPy to PyTorch tensors, since we learnt to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p34RclVKpnl0",
    "outputId": "9d89895d-2d82-41f6-f715-46994cb84e95"
   },
   "outputs": [],
   "source": [
    "# Here we print the shapes of the two returned tensors\n",
    "print(f\"Shape of input data: {X.shape}\")\n",
    "print(f\"Shape of targets: {y.shape}\")\n",
    "# Here we inspect the ranges of the elements of X and y\n",
    "print(f\"Minimum and maximum values in X. Min={X.min()} Max={X.max()}\")\n",
    "\n",
    "# Here we inspect the data types of the NumPy tensors\n",
    "print(f\"Data type of X: {X.dtype}\")\n",
    "print(f\"Data type of y: {y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYyaFzjrtfyZ"
   },
   "source": [
    "From what we printed above we deduct the following information. The size of the input tensor $X$ is $70$k $\\times 28^2$, i.e. each row of $X$ represents the $28\\times 28$ digit image, linearized. The range of gray-scale values is $[0,255]$. The entries of $X$ are `float64`. As for $y$ we have one entry for each image, holding the relative class label. However the data type of the elements of $y$ is `object`. To actually figure out the real datatype, we inspect the content and type of the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjaj2AZjtgrb",
    "outputId": "3b141ae4-5ca0-44f9-de48-57202f423a3e"
   },
   "outputs": [],
   "source": [
    "# Since the data type of y is not numeric but generic, we inspect the\n",
    "# single elements\n",
    "print(f\"Content of y[0]: {y[0]}, type of y[0]: {type(y[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5IAPWUrefyS"
   },
   "source": [
    "We will now use matplotlib to visualize some digits with the corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "bX7pOq8xbwJM",
    "outputId": "60f36937-bdf8-42a6-ac09-96d0517de13a"
   },
   "outputs": [],
   "source": [
    "# Import libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Here we plot the first 10 images in the dataset on two rows with their labels\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    ax[i // 5, i % 5].imshow(X[i].reshape(28, 28), cmap=\"gray\")\n",
    "    ax[i // 5, i % 5].axis(\"off\")\n",
    "    ax[i // 5, i % 5].set_title(y[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8GduCXFAWQt"
   },
   "source": [
    "Next, we have to reduce the number of samples from $70$k to $20$k since we will work with a reduced set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HTOhn07X68d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We keep track of the original data\n",
    "X_full = X\n",
    "y_full = y\n",
    "\n",
    "# We select a subset of random 20k training samples\n",
    "n_samples = 20000\n",
    "idx = np.random.choice(X.shape[0], n_samples, replace=False)\n",
    "X = X[idx]\n",
    "y = y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_tg2EfxX3Vs"
   },
   "source": [
    "Then, we have to split the data into a training set, validation set and test set of $10$k, $5$k and $5$k, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZixcVSrAr0e",
    "outputId": "6037f477-7343-4706-bfb9-89f00ab2a00b"
   },
   "outputs": [],
   "source": [
    "# Compute the size of the three sets: training, validation ,test\n",
    "split_sizes = [10000, 5000, 5000]\n",
    "\n",
    "# We split the tensor according to the specified sizes using torch.split\n",
    "X_train, X_val, X_test = np.split(X, np.cumsum(split_sizes)[:-1])\n",
    "y_train, y_val, y_test = np.split(y, np.cumsum(split_sizes)[:-1])\n",
    "\n",
    "# Here we print the shapes of the three sets\n",
    "print(f\"Shape of training set: {X_train.shape}\")\n",
    "print(f\"Shape of validation set: {X_val.shape}\")\n",
    "print(f\"Shape of test set: {X_test.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JlFv0_--Vzx3"
   },
   "source": [
    "To recap, the training set images are stored as rows of the 2D vector $X_\\text{tr}$ and the relative class labels are stored in the 1D vector $y_\\text{tr}$. Similarly we have the validation set in $X_\\text{val}$ and $y_\\text{val}$, and the test set in $X_\\text{ts}$ and $y_\\text{ts}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hy869pNH10dz"
   },
   "source": [
    "## Evaluation metrics\n",
    "We consider three evaluation metrics:\n",
    "* Global Accuracy (Acc): $\\frac{\\text{correctly classified images}}{\\text{of images}}$\n",
    "* Class Averaged Accuracy (mAcc)\n",
    "* Class averaged Intersection-over-Union (mIoU)\n",
    "\n",
    "We write a function to compute the three error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2lqMwGYED4o"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "def evaluate(yt, yp, num_classes=10):\n",
    "    # Computes the three metrics Acc, mAcc and mIoU\n",
    "    # yt: 1D tensor of size n with the target class labels\n",
    "    # yp: 1D tensor of size n with the predicted class labels\n",
    "    # num_classes: total number of classes\n",
    "\n",
    "    # Compute the confusion matrix C, where C_ij represents the number of images\n",
    "    # of class i classified with class j\n",
    "    # C = np.zeros((num_classes, num_classes))\n",
    "    # for i in range(yt.shape[0]):\n",
    "    #   C[yt[i], yp[i]] += 1\n",
    "\n",
    "    # Alternatively one can use sklearn.metrics.confusion_matrix(yt,yp)\n",
    "    C = sklearn.metrics.confusion_matrix(yt, yp)\n",
    "\n",
    "    return {\n",
    "        # The diagonal of C holds the images that have been correctly classified, so\n",
    "        # Acc can be computed as the sum of the diagonal divided by the number of images\n",
    "        \"Acc\": C.diagonal().sum().item() / C.sum().item(),\n",
    "        # For mAcc we need to divide the diagonal of C by the sum of each row of C\n",
    "        # because the latter represents the number of images per class. This yields\n",
    "        # a tensor with the per-class accuracies. Finally, we average the result to\n",
    "        # get the mean per-class accuracy.\n",
    "        \"mAcc\": (C.diagonal() / C.sum(-1)).mean().item(),\n",
    "        # For the IoU computation we divide the diagonal of C by the sum of the columns\n",
    "        # of C plus the sum of the rows of C minus the diagonal of C. This yeilds per-class\n",
    "        # IoUs, which are finally averaged.\n",
    "        \"mIoU\": (C.diagonal() / (C.sum(0) + C.sum(1) - C.diagonal())).mean().item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPiAI0MX0Yk9"
   },
   "source": [
    "## Machine learning classification models\n",
    "We will train the following machine learning models using scikit-learn, which have been addressed during the course:\n",
    "\n",
    "* Nearest Neghbour Classifier (seen last time)\n",
    "* Decision Tree Classifier\n",
    "* Random Forest\n",
    "* Support Vector Machines\n",
    "\n",
    "For each model we will make an analysis of its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uY-vbElLDbo"
   },
   "source": [
    "### Nearest Neighbor (NN) Classifier\n",
    "\n",
    "A Nearest Neighbor classifier is a non-parametric model that has no learnable parameters, but uses the entire training set every time it requires to perform a prediction. Indeed, given an input sample to predict, the NN classifier first retrieves a number of training samples that are close to the one we intend to predict, according to a predefined distance metric, and determines the output class from a possibly-weighted voting procedure. In order to perform inference in an efficient way, the NN classifier adopts typically tree-based datastructures to speedup the search for neighbors. \n",
    "\n",
    "In scikit-learn we can create a nearest neighbor classifier using the class [`neighbors.KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) or [`neighbors.RadiusNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html#sklearn.neighbors.RadiusNeighborsClassifier) depending on the type of NN algorithm we want to use. The former one searches for a fixed number of $K$ closest neighbors, while the latter searches for neighbors within a maximum radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRQ7nwihr8_v"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Visualize help of KNN\n",
    "neighbors.KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72G0x7mor8_v"
   },
   "source": [
    "The constructor of `neighbors.KNeighborsClassifier` admits different arguments. The most relevant ones are `n_neighbors`, which is the desired number of neighbors $K$, `weights` (uniform or distance or user-defined) which specifies how the importance of a neighbor should be weighted, `metric` the distance metric to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Z7h8YrCatQR"
   },
   "source": [
    "We start by creating a KNN classifier with default parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN0Ik_x7bEwE"
   },
   "outputs": [],
   "source": [
    "# We initialize the nearest neighbor classifier.\n",
    "# Since inference can be very slow, we enable the use of multiple processes with n_jobs=-1\n",
    "knn_model = neighbors.KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWM7ePUCbPTQ"
   },
   "source": [
    "Next we run [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit) on the training data in order to \"train\" the classifier. This will trigger the creation of the necessary datastructures that allows to quickly identify nearest neighbors during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBqkfbZlbLBW",
    "outputId": "60d73dfc-4ac0-4887-c985-fd513d41cc04"
   },
   "outputs": [],
   "source": [
    "# We will track the training/inference times of each method\n",
    "import time\n",
    "\n",
    "exec_times = {}\n",
    "scores = {}\n",
    "# We train a KNN model and track time\n",
    "# It takes some seconds\n",
    "start = time.time()\n",
    "knn_model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "exec_times[\"train\"] = {\"kNN\": end - start}\n",
    "\n",
    "print(f\"Training time: {exec_times['train']['kNN']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNGkK_ALbvnO"
   },
   "source": [
    "We take now a random validation digit, visualize it and predict it with [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "ARB38a3UcWex",
    "outputId": "9ca71f49-00ea-4e0e-f98b-7684ab7b9e53"
   },
   "outputs": [],
   "source": [
    "query_idx = np.random.randint(0, X_val.shape[0])\n",
    "sample = X_val[query_idx]\n",
    "\n",
    "# Compute the prediction for the first validation image\n",
    "prediction_knn = knn_model.predict(sample.reshape(1, -1))[0]\n",
    "\n",
    "sample = sample.reshape(28, 28)\n",
    "# Plot the digit and in the title we report the ground-truth label and the predicted one\n",
    "plt.imshow(sample, cmap=\"gray\")\n",
    "plt.title(f\"Ground-truth: {y_val[query_idx]}, prediction: {prediction_knn}\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "br0A1WckdBFe"
   },
   "source": [
    "Next we inspect what were the nearest neighbors for this validation image. We can use the method [`kneighbors`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors). The latter function returns the indices of the nearest neghbors and their distance to the query points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "ZOnVeTgHdRPN",
    "outputId": "94c199e5-02b4-4557-ef37-9d0be2086327"
   },
   "outputs": [],
   "source": [
    "def plot_neighbors(knn_model, query):\n",
    "    # Compute the nearest neighbors\n",
    "    query = query.reshape(1, -1)\n",
    "    neighbors_dist, neighbors_idx = knn_model.kneighbors(query)\n",
    "\n",
    "    # We Visualize them\n",
    "    for i, (d, idx) in enumerate(zip(neighbors_dist[0], neighbors_idx[0])):\n",
    "        ax = plt.subplot(1, len(neighbors_idx[0]), i + 1)\n",
    "        ax.axis(\"off\")\n",
    "        plt.imshow(X_train[idx].reshape(28, 28), cmap=\"gray\")\n",
    "        plt.title(f\"{y_train[idx]}\")\n",
    "\n",
    "    print(f\"Distance to neighbors: {neighbors_dist[0]}\")\n",
    "\n",
    "\n",
    "plot_neighbors(knn_model, X_val[query_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-29odoum1Ug"
   },
   "source": [
    "Due to the slowness of the inference procedure, we skip the use of the validation set for model selection (e.g. find an optimal value of the number of neighbors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xsdtbMZgCnq"
   },
   "source": [
    "We will now predict the entire training and validation set and report performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3EIkotKgG3l",
    "outputId": "933b6612-a664-419b-8e2b-2a3d9e26bcc6"
   },
   "outputs": [],
   "source": [
    "# Compute prediction for the training and validation set and track time\n",
    "knn_prediction_train = knn_model.predict(X_train)\n",
    "\n",
    "start = time.time()\n",
    "knn_prediction_val = knn_model.predict(X_val)\n",
    "end = time.time()\n",
    "\n",
    "exec_times[\"val\"] = {\"kNN\": end - start}\n",
    "\n",
    "# Print the validation performance\n",
    "print(f\"Performance on training: {evaluate(y_train, knn_prediction_train)}\")\n",
    "print(f\"Performance on validation: {evaluate(y_val, knn_prediction_val)}\")\n",
    "print(f\"Evaluation time: {exec_times['val']['kNN']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "QmnZTBhgJFdN",
    "outputId": "ada8bc0a-e1ca-41f9-c057-e811cd0c8650"
   },
   "outputs": [],
   "source": [
    "def visualize_failure_cases(X, yt, yp, num_failures_to_show=6):\n",
    "    # Visualizes failure cases and return the indices of the visualized images\n",
    "    # X: input data as a 2D tensor n x 28**2, each row being a linearized 28x28 image\n",
    "    # yt: 1D tensor with n ground-truth labels\n",
    "    # yp: 1D tensor with n predictions\n",
    "\n",
    "    # returns indices of images that have been visualized\n",
    "\n",
    "    # We determine which images are misclassified and store this in a boolean 1D tensor\n",
    "    failures = yt != yp\n",
    "    # We look for the indices of misclassified images and retain only the first num_failures_to_show ones.\n",
    "    failures_to_show = np.where(failures)[0][:num_failures_to_show]\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    # We plot the images where we are failing. i.e. the one  with indec in failures_to_show\n",
    "    # Each plot shows prediction vs target as title\n",
    "    for i, failure_idx in enumerate(failures_to_show):\n",
    "        ax = plt.subplot(1, num_failures_to_show, i + 1)\n",
    "        ax.axis(\"off\")\n",
    "        plt.imshow(X[failure_idx].reshape(28, 28), cmap=\"gray\")\n",
    "        plt.title(f\"GT: {yt[failure_idx]}, P: {yp[failure_idx]}\")\n",
    "    return failures_to_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaJXTsZqOtSK"
   },
   "source": [
    "We will next inspect some failure cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "FDT8eF79Ov9r",
    "outputId": "57993183-0558-4313-ec76-52110db3dec1"
   },
   "outputs": [],
   "source": [
    "# This visualizes some failure cases\n",
    "failure_cases = visualize_failure_cases(X_val, y_val, knn_prediction_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHJ0aSoFls6W"
   },
   "source": [
    "Next, we visualize the nearest neighbors of the first failure case in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "_8KETdlPltfY",
    "outputId": "e2ec5763-b696-42ce-bd79-8e9d5b820667"
   },
   "outputs": [],
   "source": [
    "# Visualize nearest neighbors of the failure case\n",
    "plot_neighbors(knn_model, X_val[failure_cases[0:1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HABxYKYdPqRz"
   },
   "source": [
    "Finally we compute the scores for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwDuhyyjP2bW",
    "outputId": "b67a95ac-334c-4666-9a41-c188560d67fd"
   },
   "outputs": [],
   "source": [
    "# Compute prediction for the test set\n",
    "# It takes roughly 1 minute.\n",
    "knn_prediction_test = knn_model.predict(X_test)\n",
    "\n",
    "scores[\"kNN\"] = evaluate(y_test, knn_prediction_test)\n",
    "\n",
    "# Print the test performance\n",
    "print(f\"Performance on test: {scores['kNN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-OePJZUXq74"
   },
   "source": [
    "### Decision Tree (DT) Classifier\n",
    "A decision tree classifier can be defined in scikit-learn using the class [tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decision%20tree#sklearn.tree.DecisionTreeClassifier).\n",
    "\n",
    "We start by importing the library and inspect the arguments of the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxfkKrRhZDLb"
   },
   "outputs": [],
   "source": [
    "# Import required library\n",
    "from sklearn import tree\n",
    "\n",
    "#This opens the documentation about the class\n",
    "tree.DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAyexmivZV9I"
   },
   "source": [
    "The instructions above import the required libraries and show the documentation about the class. We can see that when we create a `DecisionTreeClassification` object we can specify with `criterion` the quality measure (gini and entropy are available), whether we want to find the best (axis-aligned) split or a random one (see `splitter`), if we want to put conditions to stop the growth (`max_depth`, `min_samples_split`, `min_samples_leaf`, `max_leaf_nodes`, `min_impurity_decrease`, `min_impurity_split`), and other arguments.\n",
    "\n",
    "We start creating a decision tree with the default parametrizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE6ax45NZKkb"
   },
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6_IrdVia2RB"
   },
   "source": [
    "Similarly to what we have seen in the polynomial regression experiment, also this scikit-learn model exposes a function [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decision%20tree#sklearn.tree.DecisionTreeClassifier.fit) that can be used to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lRCyRfua0oc",
    "outputId": "d0c1fd51-0514-4ff1-bace-c8a3149b69c1"
   },
   "outputs": [],
   "source": [
    "# We will track the training/inference times of each method\n",
    "import time\n",
    "\n",
    "# Trains a decision tree on the training set\n",
    "# The execution takes few seconds\n",
    "start = time.time()\n",
    "dtree.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "exec_times[\"train\"][\"DT\"] = end - start\n",
    "\n",
    "print(f\"Training time: {exec_times['train']['DT']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dtrI8rIdiNL"
   },
   "source": [
    "We can now gather some information about the trained model, in particular depth and number of leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_TB1FYZczdS",
    "outputId": "77342af2-7e3b-4c5f-d97a-95e12d738055"
   },
   "outputs": [],
   "source": [
    "# Depth\n",
    "print(f\"Depth: {dtree.get_depth()}\")\n",
    "\n",
    "# Number of leaves\n",
    "print(f\"Number of leaves: {dtree.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-O0hwRrzgiBM"
   },
   "source": [
    "We can further inspect the trained tree which is stored in `dtree.tree_`. We refer to the documentation about [tree structure](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py) for more details. \n",
    "\n",
    "The tree is stored in terms of several arrays, being fields of `dtree.tree_`:\n",
    "* `children_left`: array where the $i$th entry represents the index of the left child of node $i$\n",
    "* `children_right`: same but for the right child\n",
    "* `node_count`: number of nodes (leaves included) in the tree\n",
    "* `feature`: array where the $i$th entry represents the index of the feature used by the split function in node $i$ (a negative value for leaves)\n",
    "* `threshold`: array where the $i$th entry represents the threshold used by the split function in node $i$ \n",
    "* `value`: array where the $i$th entry holds the class probability distribution of training samples reaching that node \n",
    "\n",
    "As an example we will inspect the rule that has been applied to split the data at the root node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFlTU6-EgdSX",
    "outputId": "5a033a24-7528-433d-8be2-d75c7377f67e"
   },
   "outputs": [],
   "source": [
    "print(f\"Feature used to split @ root: {dtree.tree_.feature[0]}\")\n",
    "print(f\"Threshold used to split @ root: {dtree.tree_.threshold[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fK8RXGcFt47G"
   },
   "source": [
    "We can visualize the position of the selected feature by plotting a black point there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "EgwK1thniH5H",
    "outputId": "68cb8053-8523-4785-fd9f-bb66ae02b53a"
   },
   "outputs": [],
   "source": [
    "# Make an image with all ones\n",
    "I = np.ones((28, 28))\n",
    "# Set to zero the feature selected for the root\n",
    "# To this end we need to view the 2D tensor as a 1D tensor and set to 0 the\n",
    "# entry corresponding to the selected feature\n",
    "I.reshape(-1)[dtree.tree_.feature[0]] = 0\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(I, cmap=\"gray\")\n",
    "plt.title(\"Position of the feature used to split data in the root node\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFt_4Pm0wazr"
   },
   "source": [
    "Next, we can plot the distribution of the selected features across all nodes, to have an idea of where the most used features are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "T5W394pEuMMT",
    "outputId": "5ae662ad-d888-41f6-d8df-7eb7041df035"
   },
   "outputs": [],
   "source": [
    "# The following two lines of code generate in feat_distrib a 1D tensor of\n",
    "# size 28**2, where each entry, say j, counts the number of occurences of the\n",
    "# jth feature\n",
    "feat_distrib = np.zeros(28**2)\n",
    "for i in range(dtree.tree_.feature.shape[0]):\n",
    "    if dtree.tree_.feature[i] >= 0:\n",
    "        feat_distrib[dtree.tree_.feature[i]] += 1\n",
    "\n",
    "# We visualize the distribution\n",
    "plt.imshow(feat_distrib.reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v90GL8V6xIbA"
   },
   "source": [
    "The saliency of the features correlates with where the digits are typically placed within the image. This way of computing the importance of the features does not take into account how many samples of the training set were split by a given feature, e.g. the split decision in the root is way more important than a split decision close to a leaf. A better estimate of the importance requires weighting each feature by the number of samples thatit splits. This can be obtained from scikit-learn using the field `dtree.feature_importances_`, which in our case is a $28**2$ long 1D tensor of weights.\n",
    "\n",
    "We visualize the properly-weighted importance of the features below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ZXDM1eLSI9GK",
    "outputId": "a3d43fae-4fb1-4f8b-8b57-83617e698dd0"
   },
   "outputs": [],
   "source": [
    "# We visualize the feature importance after properly reshaping it in a 28x28 2D tensor\n",
    "plt.imshow(dtree.feature_importances_.reshape(28, 28), cmap=\"gray\")\n",
    "plt.title(\"Normalized feature importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70Larr5AIzkV"
   },
   "source": [
    "Next we inspect the class distribution of the training set after the split in the root node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a histogram of class labels of images routed left at the root\n",
    "\n",
    "# We determine the indices of the images routed left at the root\n",
    "left_idx = np.where(X_train[:, dtree.tree_.feature[0]] < dtree.tree_.threshold[0])[0]\n",
    "\n",
    "# We determine the class labels of the images routed left at the root\n",
    "left_labels = y_train[left_idx]\n",
    "right_labels = y_train[~left_idx]\n",
    "\n",
    "# count each class label, knowing that the labels are strings\n",
    "left_labels_count = np.unique(left_labels, return_counts=True)\n",
    "right_labels_count = np.unique(right_labels, return_counts=True)\n",
    "\n",
    "# We plot the histogram as difference between the two distributions\n",
    "dist = left_labels_count[1] - right_labels_count[1]\n",
    "plt.bar(left_labels_count[0], dist)\n",
    "plt.title(\"Difference in class distribution between left and right branches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjwF4syU9TZk"
   },
   "source": [
    "We can additionally try to visualize the average image of digits being routed to the left and to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average digit from images routed to the left, X_train is numpy array\n",
    "mean_left = np.mean(X_train[left_idx], axis=0)\n",
    "mean_right = np.mean(X_train[~left_idx], axis=0)\n",
    "\n",
    "# Plot the average digits in a subplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mean_left.reshape(28, 28), cmap=\"gray\")\n",
    "plt.title(\"Average digit routed left\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mean_right.reshape(28, 28), cmap=\"gray\")\n",
    "plt.title(\"Average digit routed right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grkT4VWC1YXL"
   },
   "source": [
    "We compute now how the trained model performs on the training data and validation data. To this end, we use the method [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict) to classify the training and validation data and use the evaluation function we have defined to compute the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yy-ODPIZytYp",
    "outputId": "9480257c-940e-4659-8da9-0641118f578b"
   },
   "outputs": [],
   "source": [
    "# Compute predictions on training data\n",
    "ytr_p = dtree.predict(X_train)\n",
    "\n",
    "# Compute predictions on validation data and track execution time\n",
    "start = time.time()\n",
    "yval_p = dtree.predict(X_val)\n",
    "end = time.time()\n",
    "exec_times[\"val\"][\"DT\"] = end - start\n",
    "\n",
    "# Print results\n",
    "print(f\"Performance on training: {evaluate(y_train, ytr_p)}\")\n",
    "print(f\"Performance on validation: {evaluate(y_val, yval_p)}\")\n",
    "print(f\"Evaluation time: {exec_times['val']['DT']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td06oqHLYK-9"
   },
   "source": [
    "We know that decision trees are prone to overfitting unless we control the complexity of the model in some way. Indeed, the performance of training is perfect, but we loose accuracy on the validation set.\n",
    "\n",
    "We will now inspect some failure cases to understand whether those are due to ambiguous digits or bad generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz-UoNjwa-cW"
   },
   "source": [
    "We will now try to train a decision tree by restricting the minimum number of samples that we have in a leaf. We will try different values of this hyperparameter. We will also consider the possibility of using a different quality measure, i.e. entropy (gini is the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PrBi7N8eL8p"
   },
   "outputs": [],
   "source": [
    "# We train 4 different models, i.e. each combination of min_samples_leaf in {1,5} and criterion in {\"gini,\"entropy\"}\n",
    "# This will take few seconds.\n",
    "dtrees = [\n",
    "    tree.DecisionTreeClassifier(min_samples_leaf=ms, criterion=criterion).fit(\n",
    "        X_train, y_train\n",
    "    )\n",
    "    for ms in [1, 5]\n",
    "    for criterion in [\"gini\", \"entropy\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUT3xGmse9Eb"
   },
   "source": [
    " We measure then the performance of each model on the validation set in order to select the best, along with the performance on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "YvGi_F1wgNNi",
    "outputId": "e29a34f8-2e8f-4916-80cc-5040b86e5622"
   },
   "outputs": [],
   "source": [
    "# We compute the predictions of each tree on the validation set in a list\n",
    "dtree_predictions_val = [dt.predict(X_val) for dt in dtrees]\n",
    "\n",
    "# We compute the performance of each model on the validation set in a list\n",
    "dtree_performance_val = [evaluate(y_val, yp) for yp in dtree_predictions_val]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "# We plot the performance of each model on each metric\n",
    "for i, metric in enumerate([\"Acc\", \"mAcc\", \"mIoU\"]):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    curve_val = [res[metric] for res in dtree_performance_val]\n",
    "    plt.plot(curve_val, \"*\", markersize=10)\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.ylabel(metric)\n",
    "    # This removes the labels from the x-axis\n",
    "    plt.xticks([])\n",
    "\n",
    "# We give a name to each model we have:\n",
    "# G1: criterion=gini, num_samples_leaf=1\n",
    "# E1: criterion=entropy, num_samples_leaf=1\n",
    "# G5: criterion=gini, num_samples_leaf=5\n",
    "# E5: criterion=entropy, num_samples_leaf=5\n",
    "dt_model_names = [\"G1\", \"E1\", \"G5\", \"E5\"]\n",
    "\n",
    "# We set the x-axis labels only for the last plot\n",
    "plt.xlabel(\"models\")\n",
    "plt.xticks(range(4), dt_model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC_S4wPumL5l"
   },
   "source": [
    "We can now identify the model yielding the best validation performance, although there are little differences across the models. We observe that the use of the entropy criterion improves over Gini when we have an unconstrained tree. We can now check whether the best model improved over the previously selected failure cases. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "Y20zGqsVl4Rv",
    "outputId": "73eb2da5-dec0-456b-ddaf-e0036c1db3c3"
   },
   "outputs": [],
   "source": [
    "# We select the best model based on the mAcc metric\n",
    "best_dt_model_idx = np.argmax([res[\"mAcc\"] for res in dtree_performance_val])\n",
    "\n",
    "failures_to_show = visualize_failure_cases(X_val, y_val, yval_p)\n",
    "# Each plot shows prediction vs target\n",
    "for i, failure_idx in enumerate(failures_to_show):\n",
    "    ax = plt.subplot(1, len(failures_to_show), i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    plt.imshow(X_val[failure_idx].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.title(\n",
    "        f\"P: {dtree_predictions_val[best_dt_model_idx][failure_idx]} vs GT: {y_val[failure_idx]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsupCCFMk3Tm"
   },
   "source": [
    "Indeed, we provide now some correct answers for some previous failure cases, but new errors could have popped up for other images. Nonetheless, from the plot above we know that overall there was an improvement on the validation set. However, this does not guarantee that the selected model achieves a better generalization error, because the selection inherited some bits of information about the validation set, thus biasing the model towards it.\n",
    "To get a better (unbiased) estimate of the generalization performance we rely on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MV5I0mCb1-7p",
    "outputId": "d03aebfd-52a1-48c7-c115-23cb118729e1"
   },
   "outputs": [],
   "source": [
    "# We compute the predictions on the test set for the best model\n",
    "test_predictions_dt = dtrees[best_dt_model_idx].predict(X_test)\n",
    "\n",
    "# We keep the scores of the selected model in scores\n",
    "# This will later hold also scores of different types of models\n",
    "scores[\"DT\"] = evaluate(y_test, test_predictions_dt)\n",
    "\n",
    "# We print the performance on the test set for the selected decision tree.\n",
    "print(f\"Performance on test set: {scores['DT']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "revG3AdGMopo"
   },
   "source": [
    "This is the score that we will use to compare against other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfjBpviFLBAY"
   },
   "source": [
    "### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEBQtkuIe8Xg"
   },
   "source": [
    "A single decision tree tends to overfit the training data, unless we reduce the tree complexity, but also in that case, the algorithm used to grow the tree does not guarantee to find a model with minimal complexity. We have seen that for this specific example, the heuristic of stopping the tree growth based on the minimum number of samples in the leaf was of little/no effect. \n",
    "\n",
    "A better approach to improve on the generalization performance is by means of ensembles of possibly uncorrelated low-bias models. Decision trees are great candidates models to form an ensemble and in order to render them less correlated we can train them by randomly sampling features and by perturbing the training set for each tree via e.g. bagging. \n",
    "\n",
    "Random Forest is a popular machine learning model that consists in an ensemble of decision trees. We can create such a model in scikit-learn via [`ensemble.RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn-ensemble-randomforestclassifier). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzzGcBZQNvoe"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn import ensemble\n",
    "\n",
    "#Visualize help\n",
    "ensemble.RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ck4iGRJNu8P"
   },
   "source": [
    "This class shares the same arguments for the constructor that we have seen for decision trees, but has also additional ones such as `n_estimators`, which holds the number of trees we want to have in the ensemble, and `boostrap`, which enables boostrapping of the training set when growing each tree (enabled by default).\n",
    "\n",
    "We have seen that the best criterion seems to be entropy over gini. Moreover, ensembles are more effective if the single models have low bias, so we do not enforce stopping criteria that reduce the complexity of single trees. We set the number of trees in the ensemble to $20$ in order to keep the training time short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9ZbFEXU-CsP"
   },
   "outputs": [],
   "source": [
    "# We create a random forest model with 10 trees and entropy criterion\n",
    "rf_model = ensemble.RandomForestClassifier(n_estimators=20, criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OiUMtNe-UkB"
   },
   "source": [
    "Next, we train the forest on the training data using the usual [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVI2QNbn-tnj",
    "outputId": "cf1a1e36-dd5a-4283-f842-70835e7dbb93"
   },
   "outputs": [],
   "source": [
    "# We train the random forest model on the training set and track training time\n",
    "start = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "exec_times[\"train\"][\"RF\"] = end - start\n",
    "\n",
    "print(f\"Training time: {exec_times['train']['RF']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sS4-8UQ-2EZ"
   },
   "source": [
    "Each trained tree can be accessed in the list `rf_model.estimators_`.\n",
    "\n",
    "We compute next the performance on training and validation using the [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict) method to classify, which internally computes the prediction of each tree in the ensemble and performs a probability-weighted voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky1_7Y76-7lQ",
    "outputId": "8c9b5082-dab2-44bd-fb03-b07b54e2c77c"
   },
   "outputs": [],
   "source": [
    "# Compute prediction for the training and validation sets and track time of validation\n",
    "rf_prediction_train = rf_model.predict(X_train)\n",
    "\n",
    "start = time.time()\n",
    "rf_prediction_val = rf_model.predict(X_val)\n",
    "end = time.time()\n",
    "\n",
    "exec_times[\"val\"][\"RF\"] = end - start\n",
    "\n",
    "# Print the training and validation performance\n",
    "print(f\"Performance on training: {evaluate(y_train, rf_prediction_train)}\")\n",
    "print(f\"Performance on validation: {evaluate(y_val, rf_prediction_val)}\")\n",
    "print(f\"Evaluation time: {exec_times['val']['RF']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G376jDiXAO6H"
   },
   "source": [
    "As we can see the performance on validation is considerably higher than what we got with a single decision tree. Also, the performance on the training set is not perfect, but almost, due to the presence of bagging, which might leave some data out from the training set of each tree.\n",
    "\n",
    "Next, we visualize some failure cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "vdXWZevMIREq",
    "outputId": "1372de0e-c89b-4081-e78e-3f7865e3aded"
   },
   "outputs": [],
   "source": [
    "# This visualizes some failure cases\n",
    "visualize_failure_cases(X_val, y_val, rf_prediction_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNQeyRFUIJSU"
   },
   "source": [
    "We will now change the number of trees in the ensemble in the range $\\{3,\\ldots,20\\}$ and report the validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "2pkTWr6VBJoy",
    "outputId": "6dc6bde5-0d5d-4346-aeb5-25040329e43f"
   },
   "outputs": [],
   "source": [
    "# Make a temporary copy of all trees in the forest\n",
    "all_trees = rf_model.estimators_\n",
    "\n",
    "# Init the forest model with only the first 2 trees\n",
    "rf_model.estimators_ = [all_trees[i] for i in range(2)]\n",
    "\n",
    "# We will now iteratively add one tree at time and compute the score\n",
    "# in order to report the performance as we add more trees to the\n",
    "# ensemble\n",
    "\n",
    "curve_val = {\"Acc\": [], \"mAcc\": [], \"mIoU\": []}\n",
    "\n",
    "# For all remaining trees\n",
    "for i in range(2, len(all_trees)):\n",
    "    # We add the next tree\n",
    "    rf_model.estimators_.append(all_trees[i])\n",
    "\n",
    "    # Compute the prediction on validation of the updated ensemble\n",
    "    rf_prediction_val = rf_model.predict(X_val)\n",
    "\n",
    "    # Evaluate the result and update the Acc, mAcc and mIoU curves\n",
    "    res = evaluate(y_val, rf_prediction_val)\n",
    "    for k in res:\n",
    "        curve_val[k].append(res[k])\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "# Finally we plot the curves for each metric\n",
    "for i, metric in enumerate(curve_val.keys()):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    plt.plot(range(3, len(all_trees) + 1), curve_val[metric], linewidth=2)\n",
    "    plt.ylabel(metric)\n",
    "    # We keep the x-axis only for the last plot\n",
    "    plt.xticks([])\n",
    "    plt.grid(axis=\"y\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.xticks(range(3, len(all_trees) + 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2syU7bpDrwv"
   },
   "source": [
    "As the number of trees in the ensemble increases, the performance on validation increases. \n",
    "\n",
    "We finally report the score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGEjTQAyEFXF",
    "outputId": "03b1dea9-822c-44f7-a6bf-e69c6a86ce19"
   },
   "outputs": [],
   "source": [
    "# Compute predictions for the test set\n",
    "rf_prediction_test = rf_model.predict(X_test)\n",
    "\n",
    "# Print the\n",
    "scores[\"RF\"] = evaluate(y_test, rf_prediction_test)\n",
    "print(f\"Performance on test: {scores['RF']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeqkvcoiT5nG"
   },
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8o1t5YOkHNb"
   },
   "source": [
    "Finally, we evaluate the performance of Support Vector Machines, namely robust linear classifiers that can become non-linear by employing suitable kernel functions. SVMs are binary by nature, but can deal with multiple classes by casting the multi-class classification problem into a sequence of binary classification problems (one-vs-all, all-vs-all, and others).\n",
    "\n",
    "In scikit-learn there are different classes that can be used to train SVMs for classification among which we find [`svm.SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC), [`svm.NuSVM`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC) and [`svm.LinearSVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC). We will use the first one, which is the SVM formulation presented during the course and can deal with kernels, as opposed to `LinearSVC`, which is faster but implements only linear SVMs. The second one is a different SVM formulation which has not been presented during the course, so it will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pavh5RTsTE9Q"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn import svm\n",
    "\n",
    "# Visualize help\n",
    "svm.SVC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tm830pXiTZ_s"
   },
   "source": [
    "The relevant arguments for the constructor are `C`, which balances the importance of the regularizer (inversely proportional), `kernel` (linear, poly, rbf, sigmoid or user-specified) which allows to specify the desired kernel function. Based on the kernel selection there are a number of kernel-specify parameters. Multi-class predictions are addressed with a all-vs-all strategy.\n",
    "\n",
    "We start by initializing a C-SVM with default parametrization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llLOV20kTJw0"
   },
   "outputs": [],
   "source": [
    "# Intialize a C-SVM model\n",
    "svm_model = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQt_teaGUoyy"
   },
   "source": [
    "Next, we train the SVM model on the training set, using the usual [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.fit) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGpAI5xLUnCA",
    "outputId": "ff9de551-57c5-4f8e-aa35-ea33b01601e9"
   },
   "outputs": [],
   "source": [
    "# Train the C-SVM on the training set and track time\n",
    "# It takes several seconds\n",
    "start = time.time()\n",
    "svm_model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "exec_times[\"train\"][\"SVM\"] = end - start\n",
    "\n",
    "print(f\"Training time: {exec_times['train']['SVM']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjaDqTCIkk5h"
   },
   "source": [
    "We can inspect the trained model using the following fields:\n",
    "* `support_`: array of indices of support vectors\n",
    "* `support_vectors_`: array of training samples representing the support vectors\n",
    "* `n_support_`: array with the number of support vectors for each class\n",
    "* `coeff_`: weights of the SVM solution (only for linear kernel)\n",
    "* `dual_coeff_`: dual variables of the SVM solution\n",
    "* `intercept_`: constant in the decision function\n",
    "\n",
    "We will print the number of support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foqWiSKElz1u",
    "outputId": "e2b8a3f3-f3c4-4488-858b-756a501f7c7a"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of support vectors per class: {svm_model.n_support_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eVc9dqyUoBZ"
   },
   "source": [
    "Next, we compute the performance on both the training and validation sets using the [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwZlwzRZcq-i",
    "outputId": "f09c2b30-fd0f-436f-9fde-6bc5b7208696"
   },
   "outputs": [],
   "source": [
    "# Compute prediction for the training and validation set and track evaluation time\n",
    "# It takes a bit more than 1 minute.\n",
    "svm_prediction_train = svm_model.predict(X_train)\n",
    "\n",
    "start = time.time()\n",
    "svm_prediction_val = svm_model.predict(X_val)\n",
    "end = time.time()\n",
    "\n",
    "exec_times[\"val\"][\"SVM\"] = end - start\n",
    "\n",
    "# Print the training and validation performance\n",
    "print(f\"Performance on training: {evaluate(y_train, svm_prediction_train)}\")\n",
    "print(f\"Performance on validation: {evaluate(y_val, svm_prediction_val)}\")\n",
    "print(f\"Evaluation time: {exec_times['val']['SVM']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gF_vlva8wAEe"
   },
   "source": [
    "We visualize some failure cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "9CguPhqywD-3",
    "outputId": "bacfaa1f-2146-43a1-883d-2d42e9560128"
   },
   "outputs": [],
   "source": [
    "failures_to_show = visualize_failure_cases(X_val, y_val, svm_prediction_val);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMBcj6jHpWP0"
   },
   "source": [
    "Now, we train several SVM models using different kernels and values of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbN9qTRCc_Kb"
   },
   "outputs": [],
   "source": [
    "# We initialize and train models with all combinations of kernel in {rbf, poly, linear}\n",
    "# and C in {0.1,1,10}. For each kernel we keep the standard parametrization\n",
    "# It takes almost 6 minutes\n",
    "svm_models = [\n",
    "    svm.SVC(kernel=kernel, C=C).fit(X_train, y_train)\n",
    "    for kernel in [\"rbf\", \"linear\", \"poly\"]\n",
    "    for C in [0.1, 1, 10]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roDUdKDXsWi-"
   },
   "source": [
    "We compute the performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "iAGAPH0HqPDe",
    "outputId": "d660b722-05b6-4889-c3a0-0995bac4ea94"
   },
   "outputs": [],
   "source": [
    "# Compute predictions on validation for each model\n",
    "# It takes 3/4 minutes\n",
    "\n",
    "svms_predictions_val = [svm.predict(X_val) for svm in svm_models]\n",
    "\n",
    "# Evaluate the performance of each model\n",
    "svms_performance_val = [evaluate(y_val, yp) for yp in svms_predictions_val]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "# Produce the plot about the performance of each model on each metric\n",
    "for i, metric in enumerate([\"Acc\", \"mAcc\", \"mIoU\"]):\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    curve_val = [res[metric] for res in svms_performance_val]\n",
    "    plt.plot(curve_val, \"*\", markersize=10)\n",
    "    plt.ylabel(metric)\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.xticks([])\n",
    "\n",
    "svm_model_names = [\n",
    "    \"R.1\",\n",
    "    \"R1\",\n",
    "    \"R10\",\n",
    "    \"L.1\",\n",
    "    \"L1\",\n",
    "    \"L10\",\n",
    "    \"P.1\",\n",
    "    \"P1\",\n",
    "    \"P10\",\n",
    "]\n",
    "plt.xticks(range(9), svm_model_names)\n",
    "plt.xlabel(\"SVM models\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW-PJkEavYBA"
   },
   "source": [
    "We select the best model and check the performance on the selected failure cases of the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "AoTRHMWMvhKh",
    "outputId": "2aca660d-115e-4d23-affb-9404ec3258a3"
   },
   "outputs": [],
   "source": [
    "# We select the best model based on the mAcc metric\n",
    "best_svm_model_idx = np.argmax([res[\"mAcc\"] for res in svms_performance_val])\n",
    "\n",
    "# We plot the images where we failing previously (stored in failures_to_show)\n",
    "# Each plot shows prediction vs target\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, failure_idx in enumerate(failures_to_show):\n",
    "    ax = plt.subplot(1, len(failures_to_show), i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    plt.imshow(X_val[failure_idx].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.title(\n",
    "        f\"P: {svms_predictions_val[best_svm_model_idx][failure_idx]} vs GT: {y_val[failure_idx]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eTcVwmowvJd"
   },
   "source": [
    "Finally we compute the performance of the best model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kB4hC4GxwzQZ",
    "outputId": "2eb371a0-ac4f-45e3-b286-4965086913d5"
   },
   "outputs": [],
   "source": [
    "# We compute the predictions on the test set for the best model\n",
    "# It takes several seconds\n",
    "test_predictions_svm = svm_models[best_svm_model_idx].predict(X_test)\n",
    "\n",
    "scores[\"SVM\"] = evaluate(y_test, test_predictions_svm)\n",
    "\n",
    "# We print the performance on the test set for the selected svm model.\n",
    "print(f\"Performance on test: {scores['SVM']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cyz14XeGqXxh"
   },
   "source": [
    "# Comparisons\n",
    "We conclude with a number of scatter plots comparing the performance of the different best models for each performance metric against the time that was required for training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "T6WzbDELrBnp",
    "outputId": "49a9cfc7-34c5-4927-d8c0-70273b62e13f"
   },
   "outputs": [],
   "source": [
    "# We retrieve the model names from the keys of the scores dictionary\n",
    "models = list(scores.keys())\n",
    "\n",
    "plot_idx = 1\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# We produce a scatter plot for each combination of metric on the y-axis and\n",
    "# training/validation time on the x-axis\n",
    "for metric in [\"Acc\", \"mAcc\", \"mIoU\"]:\n",
    "    for dataset in [\"train\", \"val\"]:\n",
    "        # We arrange the plots into a 3x2 grid\n",
    "        plt.subplot(3, 2, plot_idx)\n",
    "        s = np.array([scores[model][metric] for model in models])\n",
    "        t = np.array([exec_times[dataset][model] for model in models])\n",
    "\n",
    "        # s = torch.tensor([scores[model][metric] for model in models])\n",
    "        # t = torch.tensor([exec_times[dataset][model] for model in models])\n",
    "\n",
    "        plt.plot(t.reshape(1, -1), s.reshape(1, -1), \"*\")\n",
    "\n",
    "        # This parts adds a label to each point in the scatter point, which in turn\n",
    "        # corresponds to a particular model\n",
    "        for i in range(len(models)):\n",
    "            plt.annotate(models[i], (t[i], s[i]))\n",
    "\n",
    "        # This adds some margin between axis and the points in the plot\n",
    "        plt.margins(0.3)\n",
    "\n",
    "        # The following if-the-else removes the y-axis from the second column of\n",
    "        # plots\n",
    "        if dataset == \"train\":\n",
    "            plt.ylabel(metric)\n",
    "        else:\n",
    "            plt.yticks([])\n",
    "\n",
    "        # The following instruction enables the xaxis only for the last row of plots\n",
    "        if metric == \"mIoU\":\n",
    "            plt.xlabel(\"{} time [s]\".format(dataset))\n",
    "        else:\n",
    "            plt.xticks([])\n",
    "\n",
    "        plot_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb-0jte_1a8h"
   },
   "source": [
    "In terms of accuracy, SVM wins the competition, although we did not conduct an extensive search of models for each type of classifier, however, it requires much longer training time compared to all other methods and longer inference time compared to RF and DT. kNNs achieve also good performance but at the cost of extremely slow inference. DTs can be trained fast and also inference is fast. However, a single tree does not generalize well. RFs, which provide an esemble of trees, provide a good trade-off of accuracy and training/inference speed. Note also that we limited ourself to $20$ trees, but larger ensembles could have been used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1. Try to improve the performance of the models by tuning the hyper-parameters. You can use the validation set for this purpose.\n",
    "2. Try other datasets, like:\n",
    "   1. (reasonably ok) CIFAR-10, which is a dataset of $32\\times32$ color images with $10$ classes. The dataset can be downloaded from [here](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "   2. (easy to load, hard to train) CIFAR-100, which is a dataset of $32\\times32$ color images with $100$ classes. The dataset can be downloaded from [here](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "   3. (hard to load, easy to train) IMDB, which is a dataset of movie reviews with $2$ classes (positive/negative). The dataset can be downloaded from [here](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). We are dealing with text data, so you will need to use a different feature extraction method, such as bag-of-words or word embeddings. A good starting point is `scikit-learn`'s [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) classes and `nlkt`'s [`word_tokenize`](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize) function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exercise is mandatory, but you are encouraged to try them out. You will learn a lot by doing so!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
